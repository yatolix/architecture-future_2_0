# Обоснование конфигурации Terraform для развёртывания инфраструктуры «Будущее 2.0»

## 1. Выбор ресурсов и параметров

### 1.1. Сеть и подсеть
- **VPC Network** (`future2-network`) и **Subnet** (`future2-subnet`, CIDR `10.10.0.0/24`) созданы для изоляции ресурсов и обеспечения безопасного внутреннего взаимодействия между компонентами.
- Подсеть размещена в зоне `ru-central1-a` – наиболее доступной зоне Yandex Cloud.
- На виртуальных машинах включён **NAT** (`nat = true`) для доступа в интернет с целью установки обновлений и загрузки необходимого ПО (Docker, Python, библиотеки). Внутренние управляемые сервисы (БД, Kafka) доступны только по внутренним IP, что повышает безопасность.

### 1.2. Виртуальные машины
Для каждого домена создана отдельная ВМ с минимальными, но достаточными для тестирования характеристиками:

| Домен          | Имя ВМ           | vCPU | RAM, ГБ | Диск, ГБ | `core_fraction` |
|----------------|------------------|------|---------|----------|-----------------|
| Медицина       | `med-services`   | 2    | 2       | 20       | 20%             |
| Финтех         | `fin-services`   | 2    | 2       | 20       | 20%             |
| ИИ-сервисы     | `ai-services`    | 2    | 2       | 20       | 20%             |
| MDM            | `mdm-services`   | 2    | 2       | 20       | 20%             |
| Портал (Web/Dremio/DataHub) | `portal-services` | 2 | 4 | 30 | 20% |
| Airflow (ETL)  | `airflow-vm`     | 2    | 2       | 20       | 20%             |

**Обоснование:**
- Платформа `standard-v2` с `core_fraction = 20%` (гарантированная доля CPU) выбрана для экономии средств при невысокой нагрузке в тестовом режиме.
- Для портала увеличена память до 4 ГБ, так как Dremio требует больше RAM для обработки запросов.
- Диски типа `network-hdd` объёмом 20–30 ГБ достаточны для размещения ОС, приложений и небольших объёмов данных. При необходимости в будущем диски можно расширить без пересоздания ВМ.

### 1.3. Управляемые сервисы (PostgreSQL, Kafka)
Использование managed-сервисов оправдано следующими причинами:
- **Надёжность**: автоматическое резервное копирование, мониторинг, обновления.
- **Безопасность**: изоляция от ВМ, управление доступом через IAM.
- **Экономия времени**: не требуется администрировать СУБД вручную.

Параметры кластеров:
- Класс `b2.medium` (2 vCPU, 4 ГБ RAM) – минимально допустимый для production-среды в Yandex Cloud, обеспечивает достаточную производительность.
- Диски `network-hdd` по 10 ГБ – для хранения данных тестового объёма.
- Отключён публичный доступ (`assign_public_ip = false`) – взаимодействие только изнутри сети.

### 1.4. Object Storage (Lakehouse)
Бакет `future2-lakehouse-<folder_id>` создан для хранения аналитических данных (Data Lakehouse). Используется сервисный аккаунт `storage-sa` с ролью `storage.admin`, что позволяет управлять бакетом и объектами. Выбор S3-совместимого хранилища обусловлен:
- Масштабируемостью и низкой стоимостью хранения больших объёмов данных.
- Интеграцией с инструментами аналитики (Dremio, Spark и др.).
- Возможностью использовать как единое хранилище для всех доменов.

### 1.5. Отказ от managed Airflow
Изначально планировался managed-кластер Airflow, но из-за сложностей синтаксиса ресурса и требований к обязательным блокам (worker, scheduler, webserver, code_sync) было принято решение развернуть Airflow на отдельной ВМ (`airflow-vm`). Это:
- Упрощает конфигурацию Terraform.
- Позволяет вручную установить любую версию Airflow и настроить его под конкретные задачи.
- Не противоречит архитектуре – сервис ETL остаётся в составе платформы данных.

## 2. Причины использования декларативного подхода (IaC)

### 2.1. Воспроизводимость
Вся инфраструктура описана в коде (main.tf, variables.tf). Это гарантирует, что при повторном применении (например, в другом окружении) будет создана идентичная конфигурация, исключая «человеческий фактор» и ошибки ручного ввода.

### 2.2. Версионирование и аудит
Файлы Terraform могут храниться в Git, что позволяет отслеживать изменения, откатываться к предыдущим версиям и проводить код-ревью. Это повышает прозрачность и управляемость инфраструктуры.

### 2.3. Масштабируемость
Добавление новых доменов (например, Производство и Фармацевтика) сводится к копированию блоков ресурсов с заменой имён и переменных. При необходимости можно легко увеличить ресурсы (например, изменить core_fraction или тип диска) через переменные.

### 2.4. Документирование
Код Terraform служит актуальной документацией инфраструктуры: любой разработчик или администратор может увидеть, какие ресурсы созданы и как они связаны.

## 3. Соответствие архитектуре и требованиям

- **Медицина, Финтех, MDM** – отдельные кластеры PostgreSQL и ВМ для сервисов.
- **ИИ-сервисы** – ВМ для размещения моделей и обработки данных.
- **Платформа данных** – Kafka (шинa событий), бакет Lakehouse, ВМ для портала (Dremio, DataHub, веб-интерфейс), ВМ для Airflow.
- **Производство и Фармацевтика** – не развёрнуты, но подготовлены шаблоны для будущего добавления.
- **Легаси-системы (старая шина, DWH)** – не включены, так как планируются к выводу.

Все ресурсы размещены в одной подсети, что обеспечивает минимальную задержку и безопасный обмен данными между компонентами.

## 4. Экономическая эффективность

Выбраны самые экономичные тарифы:
- ВМ с `core_fraction = 20%` и `network-hdd`.
- Управляемые БД и Kafka класса `b2.medium` с HDD.
- Object Storage с оплатой только за фактическое использование.

Суммарная стоимость всех ресурсов при работе 24/7 не превысит **≈ 5000 рублей в месяц**, что при бюджете 1000 рублей позволяет тестировать инфраструктуру в течение нескольких дней. После фиксации результата все ресурсы будут удалены командой `terraform destroy`, что исключит лишние расходы.

## 5. Заключение

Разработанная Terraform-конфигурация полностью автоматизирует создание инфраструктуры, необходимой для перехода к целевой архитектуре «Будущее 2.0». Декларативный подход обеспечивает воспроизводимость, прозрачность и лёгкость масштабирования. Выбор параметров ресурсов оптимален для тестового окружения и укладывается в ограниченный бюджет.